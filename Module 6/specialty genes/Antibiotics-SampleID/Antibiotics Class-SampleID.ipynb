{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28f8f48-6bde-4eb6-8261-687b921c101b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\style\\core.py:137\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:866\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    865\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 866\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_or_url(fname) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:843\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    842\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[1;32m--> 843\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-whitegrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaxNLocator\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Setting visualization aesthetics\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn-whitegrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# ## Data Acquisition and Validation\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Define file paths with flexible configuration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\style\\core.py:139\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Antibiotic Sample Classification Analysis\n",
    "# ==========================================\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Setting visualization aesthetics\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Acquisition and Validation\n",
    "\n",
    "# %%\n",
    "# Define file paths with flexible configuration\n",
    "input_file = \"datasets/Antibiotics-SampleID.csv\"\n",
    "output_heatmap = \"Antibiotics_Sample_Classification_heatmap.png\"\n",
    "output_matrix_csv = \"Antibiotics_Sample_Matrix_Data.csv\"\n",
    "\n",
    "# File verification with path detection protocol\n",
    "def validate_file_path(file_path):\n",
    "    \"\"\"\n",
    "    Validates file existence and searches for alternatives if not found.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Primary target file path\n",
    "    \n",
    "    Returns:\n",
    "    str: Valid file path or raises FileNotFoundError\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File located: {file_path}\")\n",
    "        return file_path\n",
    "        \n",
    "    # Generate alternative path variations\n",
    "    filename = os.path.basename(file_path)\n",
    "    name_parts = os.path.splitext(filename)\n",
    "    possible_alternatives = [\n",
    "        filename,\n",
    "        name_parts[0].replace(\" \", \"_\") + name_parts[1],\n",
    "        name_parts[0].replace(\"-\", \"\") + name_parts[1],\n",
    "        name_parts[0].replace(\"-\", \"_\") + name_parts[1],\n",
    "        name_parts[0].replace(\" \", \"\") + name_parts[1]\n",
    "    ]\n",
    "    \n",
    "    # Search for alternatives in current directory\n",
    "    for alt_name in possible_alternatives:\n",
    "        if os.path.exists(alt_name):\n",
    "            print(f\"Located alternative file: {alt_name}\")\n",
    "            return alt_name\n",
    "    \n",
    "    raise FileNotFoundError(f\"Unable to locate target file: {file_path}\")\n",
    "\n",
    "# Validate and set correct file path\n",
    "input_file = validate_file_path(input_file)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Loading and Preprocessing\n",
    "\n",
    "# %%\n",
    "# Load and examine data structure\n",
    "data = pd.read_csv(input_file)\n",
    "print(\"Initial data dimensions:\", data.shape)\n",
    "print(\"\\nColumn headers:\")\n",
    "print(data.columns.tolist())\n",
    "print(\"\\nFirst rows preview:\")\n",
    "data.head()\n",
    "\n",
    "# %%\n",
    "# Data structure examination and transformation\n",
    "def preprocess_antibiotics_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the antibiotics dataset by handling headers, indices,\n",
    "    and converting data types appropriately.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Raw input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Processed dataframe ready for analysis\n",
    "    \"\"\"\n",
    "    # Create a copy to preserve original data\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Header structure processing - check if first row contains headers\n",
    "    if 'Sample ID' in processed_df.columns:\n",
    "        print(\"Using 'Sample ID' as index column\")\n",
    "        id_column = 'Sample ID'\n",
    "    elif 'Unnamed: 0' in processed_df.columns:\n",
    "        print(\"Renaming 'Unnamed: 0' to 'Sample ID'\")\n",
    "        processed_df = processed_df.rename(columns={'Unnamed: 0': 'Sample ID'})\n",
    "        id_column = 'Sample ID'\n",
    "    elif processed_df.columns[0] == '':\n",
    "        print(\"Renaming first column to 'Sample ID'\")\n",
    "        processed_df = processed_df.rename(columns={processed_df.columns[0]: 'Sample ID'})\n",
    "        id_column = 'Sample ID'\n",
    "    else:\n",
    "        # Use first column as ID\n",
    "        print(\"Using first column as index\")\n",
    "        id_column = processed_df.columns[0]\n",
    "    \n",
    "    # Set index and remove any unnamed columns that are entirely empty\n",
    "    processed_df = processed_df.set_index(id_column)\n",
    "    empty_cols = [col for col in processed_df.columns if 'Unnamed' in col and processed_df[col].isna().all()]\n",
    "    if empty_cols:\n",
    "        print(f\"Removing {len(empty_cols)} empty unnamed columns\")\n",
    "        processed_df = processed_df.drop(columns=empty_cols)\n",
    "    \n",
    "    # Try to convert numeric columns, coercing errors to NaN\n",
    "    for col in processed_df.columns:\n",
    "        try:\n",
    "            processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')\n",
    "        except:\n",
    "            print(f\"Column '{col}' contains non-numeric data\")\n",
    "    \n",
    "    # Fill NaN values with 0 for numeric analysis\n",
    "    processed_df = processed_df.fillna(0)\n",
    "    \n",
    "    # Check if any columns should be converted to integer type\n",
    "    for col in processed_df.columns:\n",
    "        if processed_df[col].dropna().apply(lambda x: x.is_integer()).all():\n",
    "            processed_df[col] = processed_df[col].astype(int)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Apply preprocessing\n",
    "processed_data = preprocess_antibiotics_data(data)\n",
    "print(\"\\nProcessed data dimensions:\", processed_data.shape)\n",
    "processed_data.head()\n",
    "\n",
    "# %%\n",
    "# Data inspection and quality assessment\n",
    "def assess_data_quality(df):\n",
    "    \"\"\"\n",
    "    Assess data quality by checking for missing values,\n",
    "    analyzing value distributions, and identifying potential issues.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of quality metrics\n",
    "    \"\"\"\n",
    "    quality_metrics = {}\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_count = df.isna().sum().sum()\n",
    "    quality_metrics['missing_values'] = missing_count\n",
    "    quality_metrics['missing_percentage'] = (missing_count / df.size) * 100\n",
    "    \n",
    "    # Check value ranges\n",
    "    quality_metrics['value_ranges'] = {\n",
    "        col: (df[col].min(), df[col].max()) for col in df.columns\n",
    "    }\n",
    "    \n",
    "    # Check for zero values\n",
    "    zero_counts = (df == 0).sum()\n",
    "    quality_metrics['zero_counts'] = zero_counts\n",
    "    quality_metrics['zero_percentage'] = (zero_counts / len(df)) * 100\n",
    "    \n",
    "    # Summary statistics\n",
    "    quality_metrics['summary_stats'] = df.describe()\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "# Analyze data quality\n",
    "quality_assessment = assess_data_quality(processed_data)\n",
    "print(\"\\nData quality assessment:\")\n",
    "print(f\"Missing values: {quality_assessment['missing_values']} ({quality_assessment['missing_percentage']:.2f}%)\")\n",
    "print(\"\\nValue ranges (min, max):\")\n",
    "for col, (min_val, max_val) in list(quality_assessment['value_ranges'].items())[:5]:\n",
    "    print(f\"  {col}: ({min_val}, {max_val})\")\n",
    "print(\"... and more columns\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Transformation and Matrix Generation\n",
    "\n",
    "# %%\n",
    "# Export processed matrix data for reference\n",
    "processed_data.to_csv(output_matrix_csv)\n",
    "print(f\"Matrix data exported to: {output_matrix_csv}\")\n",
    "\n",
    "# %%\n",
    "# Label truncation with mapping preservation for visualization clarity\n",
    "def create_label_mappings(df, row_length_threshold=20, col_length_threshold=15):\n",
    "    \"\"\"\n",
    "    Creates mappings for long row and column labels to improve visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    row_length_threshold (int): Maximum length for row labels\n",
    "    col_length_threshold (int): Maximum length for column labels\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (modified dataframe, row mapping dict, column mapping dict)\n",
    "    \"\"\"\n",
    "    modified_df = df.copy()\n",
    "    \n",
    "    # Create row label mapping\n",
    "    row_label_mapping = {}\n",
    "    for idx, label in enumerate(modified_df.index):\n",
    "        if len(str(label)) > row_length_threshold:\n",
    "            shortened = f\"Sample {idx+1}\"\n",
    "            row_label_mapping[shortened] = str(label)\n",
    "            modified_df.rename(index={label: shortened}, inplace=True)\n",
    "    \n",
    "    # Create column label mapping\n",
    "    column_label_mapping = {}\n",
    "    for idx, col in enumerate(modified_df.columns):\n",
    "        if len(str(col)) > col_length_threshold:\n",
    "            shortened = f\"Cat. {idx+1}\"\n",
    "            column_label_mapping[shortened] = str(col)\n",
    "            modified_df.rename(columns={col: shortened}, inplace=True)\n",
    "    \n",
    "    return modified_df, row_label_mapping, column_label_mapping\n",
    "\n",
    "# Apply label mapping\n",
    "visualization_data, row_mapping, column_mapping = create_label_mappings(processed_data)\n",
    "print(f\"Created {len(row_mapping)} row mappings and {len(column_mapping)} column mappings\")\n",
    "visualization_data.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Visualization Generation\n",
    "\n",
    "# %%\n",
    "# Configure optimal figure dimensions\n",
    "def calculate_figure_dimensions(df):\n",
    "    \"\"\"\n",
    "    Calculate optimal figure dimensions based on dataframe size.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (width, height) in inches\n",
    "    \"\"\"\n",
    "    # Base dimensions\n",
    "    base_width = 10\n",
    "    base_height = 8\n",
    "    \n",
    "    # Scale based on data dimensions\n",
    "    width_scale = max(1, df.shape[1] / 5)\n",
    "    height_scale = max(1, df.shape[0] / 10)\n",
    "    \n",
    "    # Calculate dimensions with constraints\n",
    "    width = min(24, max(base_width, base_width * width_scale))\n",
    "    height = min(16, max(base_height, base_height * height_scale))\n",
    "    \n",
    "    return width, height\n",
    "\n",
    "# Calculate figure dimensions\n",
    "fig_width, fig_height = calculate_figure_dimensions(visualization_data)\n",
    "print(f\"Optimal figure dimensions: {fig_width:.1f} x {fig_height:.1f} inches\")\n",
    "\n",
    "# %%\n",
    "# Generate heatmap visualization\n",
    "def generate_heatmap(df, row_mapping=None, column_mapping=None, width=12, height=10, \n",
    "                    title=\"Antibiotic Sample Classification Heatmap\", \n",
    "                    output_file=None):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive heatmap visualization with label mappings.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Data for visualization\n",
    "    row_mapping (dict): Mapping of shortened row labels to original\n",
    "    column_mapping (dict): Mapping of shortened column labels to original\n",
    "    width (float): Figure width in inches\n",
    "    height (float): Figure height in inches\n",
    "    title (str): Plot title\n",
    "    output_file (str): Path to save the figure\n",
    "    \n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Initialize figure\n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    # Create custom color gradient: black (low) -> green (mid) -> red (high)\n",
    "    cmap = plt.cm.colors.LinearSegmentedColormap.from_list(\n",
    "        \"custom\", [\"#000000\", \"#006400\", \"#8B0000\"], N=256)\n",
    "    \n",
    "    # Generate heatmap with enhanced parameters\n",
    "    heatmap = sns.heatmap(\n",
    "        df,\n",
    "        cmap=cmap,\n",
    "        cbar=True,\n",
    "        square=False,\n",
    "        xticklabels=True,\n",
    "        yticklabels=True,\n",
    "        linewidths=0.5,\n",
    "        linecolor='white',\n",
    "        annot=True,\n",
    "        fmt='.1f' if df.dtypes[0] == float else 'g',\n",
    "        annot_kws={\"size\": 9},\n",
    "        robust=True,\n",
    "        cbar_kws={\"shrink\": 0.5, \"label\": \"Value Magnitude\"}\n",
    "    )\n",
    "    \n",
    "    # Configure typography\n",
    "    plt.xticks(fontsize=10, rotation=45, ha='right')\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    # Title and labels\n",
    "    plt.title(title, fontsize=16, pad=20)\n",
    "    plt.ylabel('Sample ID', fontsize=14, labelpad=15)\n",
    "    \n",
    "    # Optimize layout\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    \n",
    "    # Add mapping information as legend if needed\n",
    "    if row_mapping or column_mapping:\n",
    "        legend_text = \"\"\n",
    "        \n",
    "        if row_mapping:\n",
    "            legend_text += \"SAMPLE ID MAPPING:\\n\"\n",
    "            # Display first 5 mappings, then count the rest\n",
    "            sorted_items = sorted(row_mapping.items())\n",
    "            for short, full in sorted_items[:5]:\n",
    "                legend_text += f\"{short}: {full}\\n\"\n",
    "            if len(sorted_items) > 5:\n",
    "                legend_text += f\"... and {len(sorted_items)-5} more sample mappings\\n\"\n",
    "        \n",
    "        if column_mapping:\n",
    "            if legend_text:\n",
    "                legend_text += \"\\n\"\n",
    "            legend_text += \"CATEGORY MAPPING:\\n\"\n",
    "            sorted_items = sorted(column_mapping.items())\n",
    "            for short, full in sorted_items[:5]:\n",
    "                legend_text += f\"{short}: {full}\\n\"\n",
    "            if len(sorted_items) > 5:\n",
    "                legend_text += f\"... and {len(sorted_items)-5} more category mappings\\n\"\n",
    "        \n",
    "        # Position legend text\n",
    "        plt.figtext(0.5, 0.01, legend_text, ha='center', fontsize=9, \n",
    "                    bbox={\"facecolor\":\"white\", \"alpha\":0.8, \"pad\":5})\n",
    "        \n",
    "        # Adjust bottom margin\n",
    "        plt.subplots_adjust(bottom=0.3)\n",
    "    \n",
    "    # Save figure if output file specified\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=150, bbox_inches='tight', pad_inches=0.5)\n",
    "        print(f\"Heatmap saved to: {output_file}\")\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "# Generate and display heatmap\n",
    "heatmap_fig = generate_heatmap(\n",
    "    visualization_data, \n",
    "    row_mapping, \n",
    "    column_mapping,\n",
    "    width=fig_width,\n",
    "    height=fig_height,\n",
    "    title=\"Antibiotic Sample Classification Heatmap\",\n",
    "    output_file=output_heatmap\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Supplementary Analysis\n",
    "\n",
    "# %%\n",
    "# Generate reference file for label mappings\n",
    "def generate_mapping_reference(row_mapping, column_mapping, output_file=\"antibiotic_label_reference.txt\"):\n",
    "    \"\"\"\n",
    "    Generate a reference file for label mappings.\n",
    "    \n",
    "    Parameters:\n",
    "    row_mapping (dict): Row label mapping dictionary\n",
    "    column_mapping (dict): Column label mapping dictionary\n",
    "    output_file (str): Output file path\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"ANTIBIOTICS SAMPLE CLASSIFICATION LABEL REFERENCE\\n\")\n",
    "        f.write(\"==============================================\\n\\n\")\n",
    "        \n",
    "        if row_mapping:\n",
    "            f.write(\"SAMPLE ID MAPPINGS:\\n\")\n",
    "            f.write(\"-----------------\\n\")\n",
    "            for short, full in sorted(row_mapping.items()):\n",
    "                f.write(f\"{short}: {full}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        if column_mapping:\n",
    "            f.write(\"CATEGORY MAPPINGS:\\n\")\n",
    "            f.write(\"----------------\\n\")\n",
    "            for short, full in sorted(column_mapping.items()):\n",
    "                f.write(f\"{short}: {full}\\n\")\n",
    "    \n",
    "    print(f\"Label reference file generated: {output_file}\")\n",
    "\n",
    "# Generate reference file if mappings exist\n",
    "if row_mapping or column_mapping:\n",
    "    generate_mapping_reference(row_mapping, column_mapping)\n",
    "\n",
    "# %%\n",
    "# Additional statistical analysis\n",
    "def perform_statistical_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform additional statistical analysis on the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of analysis results\n",
    "    \"\"\"\n",
    "    analysis = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    analysis['basic_stats'] = df.describe()\n",
    "    \n",
    "    # Correlation analysis\n",
    "    if df.shape[1] > 1:  # Only if multiple columns\n",
    "        analysis['correlation'] = df.corr()\n",
    "    \n",
    "    # Column sums and means\n",
    "    analysis['column_sums'] = df.sum()\n",
    "    analysis['column_means'] = df.mean()\n",
    "    \n",
    "    # Row sums and means\n",
    "    analysis['row_sums'] = df.sum(axis=1)\n",
    "    analysis['row_means'] = df.mean(axis=1)\n",
    "    \n",
    "    # Identify top samples by total value\n",
    "    row_totals = df.sum(axis=1).sort_values(ascending=False)\n",
    "    analysis['top_samples'] = row_totals.head(5)\n",
    "    analysis['bottom_samples'] = row_totals.tail(5)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Perform statistical analysis\n",
    "stat_analysis = perform_statistical_analysis(processed_data)\n",
    "print(\"\\nStatistical Analysis Summary:\")\n",
    "print(\"\\nTop 5 samples by total value:\")\n",
    "print(stat_analysis['top_samples'])\n",
    "print(\"\\nBottom 5 samples by total value:\")\n",
    "print(stat_analysis['bottom_samples'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Distribution Visualization\n",
    "\n",
    "# %%\n",
    "# Generate distribution plots\n",
    "def visualize_distributions(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for data distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Plot 1: Overall distribution of all values\n",
    "    all_values = df.values.flatten()\n",
    "    sns.histplot(all_values, bins=30, kde=True, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Distribution of All Values')\n",
    "    axes[0, 0].set_xlabel('Value')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot 2: Row sums distribution\n",
    "    row_sums = df.sum(axis=1)\n",
    "    sns.histplot(row_sums, bins=20, kde=True, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Distribution of Sample Totals')\n",
    "    axes[0, 1].set_xlabel('Total Value')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot 3: Column sums distribution\n",
    "    col_sums = df.sum()\n",
    "    sns.barplot(x=col_sums.index, y=col_sums.values, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Category Totals')\n",
    "    axes[1, 0].set_xlabel('Category')\n",
    "    axes[1, 0].set_ylabel('Total Value')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    # Plot 4: Box plot of columns\n",
    "    sns.boxplot(data=df, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Value Distribution by Category')\n",
    "    axes[1, 1].set_xlabel('Category')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('antibiotic_distributions.png', dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate distribution visualizations\n",
    "dist_fig = visualize_distributions(processed_data)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Hierarchical Clustering Analysis\n",
    "\n",
    "# %%\n",
    "# Perform hierarchical clustering\n",
    "def perform_clustering(df):\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering on samples and categories.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: Clustered heatmap figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Generate clustered heatmap\n",
    "    clustered_heatmap = sns.clustermap(\n",
    "        df,\n",
    "        cmap=plt.cm.colors.LinearSegmentedColormap.from_list(\n",
    "            \"custom\", [\"#000000\", \"#006400\", \"#8B0000\"], N=256),\n",
    "        figsize=(fig_width, fig_height),\n",
    "        dendrogram_ratio=0.1,\n",
    "        colors_ratio=0.03,\n",
    "        row_cluster=True,\n",
    "        col_cluster=True,\n",
    "        linewidths=0.5,\n",
    "        annot=df.shape[0] < 20 and df.shape[1] < 15,  # Only annotate if not too large\n",
    "        fmt='.1f' if df.dtypes[0] == float else 'g',\n",
    "        robust=True,\n",
    "        cbar_kws={\"label\": \"Value Magnitude\"}\n",
    "    )\n",
    "    \n",
    "    # Adjust labels\n",
    "    plt.setp(clustered_heatmap.ax_heatmap.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    plt.setp(clustered_heatmap.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "    \n",
    "    # Add title\n",
    "    plt.suptitle(\"Hierarchical Clustering of Antibiotic Samples\", fontsize=16, y=1.02)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('antibiotic_clustering.png', dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    return clustered_heatmap\n",
    "\n",
    "# Generate clustered heatmap\n",
    "clustered_fig = perform_clustering(processed_data)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Summary and Conclusions\n",
    "\n",
    "# %%\n",
    "# Generate summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total samples analyzed: {processed_data.shape[0]}\")\n",
    "print(f\"Total categories: {processed_data.shape[1]}\")\n",
    "print(f\"Data range: {processed_data.values.min()} to {processed_data.values.max()}\")\n",
    "print(f\"Mean value: {processed_data.values.mean():.2f}\")\n",
    "print(f\"Median value: {np.median(processed_data.values):.2f}\")\n",
    "print(f\"Standard deviation: {processed_data.values.std():.2f}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Analysis complete. Output files generated:\")\n",
    "print(f\"- {output_matrix_csv}\")\n",
    "print(f\"- {output_heatmap}\")\n",
    "print(\"- antibiotic_distributions.png\")\n",
    "print(\"- antibiotic_clustering.png\")\n",
    "if row_mapping or column_mapping:\n",
    "    print(\"- antibiotic_label_reference.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041b340-9075-40fc-9b4d-6b5502b39777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
